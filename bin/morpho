#!/usr/bin/env python2.7
from itertools import product, chain
from collections import defaultdict
from multiprocessing.dummy import Pool
from subprocess import call
import os, errno, random, glob, sys
import os.path
import argparse

# infrastructure 

def mkdir_p(path):
  try:
    os.makedirs(path)
  except OSError as exc: # Python >2.5
    if exc.errno == errno.EEXIST and os.path.isdir(path):
      pass
    else: raise

class datafile: 
  def __init__(self, path): 
    self.path = path 
    self.abspath = os.path.abspath(path)
    self.basename = os.path.basename(path)
    self.dirname = os.path.dirname(path)
    self.stem = os.path.splitext(self.basename)[0]
  def exists(self): 
    return os.path.isfile(self.realpath)
  def __str__(self):
    return self.abspath

class out(datafile):
  pass

class image(datafile):
  def objects(self):
    return glob.glob('{0.dirname}/../objects/*.obj'.format(self))
  def labels(self):
    return glob.glob('{0.dirname}/../labels/{0.stem}_labels.mnc'.format(self))

class command:
  def __init__(self, fmt_string, *args, **kwargs):
    cmdstr = fmt_string.format(*args,**kwargs)
    self.__init__(shlex.split(cmdstr))  # split it up into parts
    #
    #todo: we could augment the usual string formatting syntax to include 
    #      the ability to indicate types (e.g. that an argument is an 'out'put
    #      file. 
    #
    #      Ideas: 
    #         # 1. use <Type>@<string> to mean 
    #         #   call Type(string), as in: 
    #         nuc_correct {0} out@{output_dir}/nuc/{0.stem} 
    #
    #         # Q: what if there are @ characters in the string?
    #         # A: too bad. :-)  But honestly, we could just check for strings
    #         that match $\w+@ so that the only strings that may get confused
    #         are those that happen to start with out@ and are NOT mean to be
    #         interpreted as types. 
    #
    #         # 2. use the conversion option for output files: o
    #         bestlinreg {from} {to} {xfm!o} {resampled!o}

  def __init__(self, *args): 
    #todo: sanity checks
    self.cmd = args

class taskset:
  def __init__(self):
    self.stages = defaultdict(list)
    self.stage_order = []
  def stage(self,stage_name):
    """syntactic sugar"""
    t = self
    class _stage(): 
      def command(self, *args):
        t.command(stage_name,args)
    return _stage()
  def command(self,stage,cmd):
    self.stages[stage].append(cmd)
    if stage not in self.stage_order: self.stage_order.append(stage)
  def set_stage_order(self, order):
    assert set(order).issubset(set(self.stages.keys)), "some stages given are not part of this taskset"
    self.stage_order = order
  def __str__(self):
    __str=""
    for stage in self.stage_order:
      __str += '{0}:\n'.format(stage)
      for command in self.stages[stage]:
        __str += '\t{0}\n'.format(' '.join(map(str,command)))
    return __str

def run_command(command): 
  cmdstr = " ".join(map(str,command))
  print >> sys.stderr, 'COMMAND:', cmdstr
  return call(cmdstr,shell=True)

class multiprocqueue:
  def run(self,tasks,processes=None,stage_order=None):
    """Runs the commands from the given stages in the task list.
       
       If stages isn't provided, then all stages are run. """
    stage_order = stage_order or tasks.stage_order
    for stage in stage_order:
      print '## stage:', stage,'##'

      results = self._run(tasks.stages[stage], processes)
      print 'results ---',results
      #TODO: assert that there were no errors
      if not all(map(lambda x: x==0,results)):
        print "Error in stage {0}. Exiting...".format(stage)
        return -1

  def _run(self,commands,processes=None): 
    unfinished, outputs = self._filter_unfinished(commands)

    # make output dirs directories
    map(mkdir_p, set(map(lambda x: x.dirname, chain(*outputs))))

    return Pool(processes).map(run_command, unfinished)

  def _filter_unfinished(self,commands):
    """returns tuple of each unfinished command, and a list of its output files"""
    details = [(c,filter(lambda x: isinstance(x,out),c)) for c in commands]
    filtered = [(c,o) for (c,o) in details if not all(map(lambda x: os.path.isfile(str(x)),o))]
    if filtered:
        unfinished, outputs = zip(*filtered)
    else:
        unfinished, outputs = (), ()
    return (unfinished, outputs)

class Morphobits:
  def __init__(self):
    self._config = dict() # runtime configuration 
    self._config['output_dir']='output'
    self._config['reg_dir']   ='registrations'

  def xfmpath(self,images,name='nl.xfm'):
    """Returns a standard path to an XFM file based on image names"""
    args=[self._config['output_dir'],self._config['reg_dir']] + [i.stem for i in images] + [name]
    return os.path.join(*args)

  def config(self, key):
    return self._config.get(key,None)

  def build_pipeline(self,atlases,native_subjects,model,tasklist=None):
    tasklist = tasklist or taskset()
    subjects = []

    # syntactic sugar for now
    def stage(stage_name):
      return tasklist.stage(stage_name)
    
    def command(command,stage):
      tasklist.stage(stage).command(*command)

    ## BEGIN
    # move to subjects to model space 
    for s in native_subjects:
      nuc=out('output/nuc/'+s.basename)
      xfm=out(self.xfmpath([model,s],name='lsq9.xfm'))
      modelsubject=out('output/modelspace/'+s.basename)
      command(('nu_correct','-quiet',s,nuc), stage='subject.nuc')
      stage('subject.model.prop').command(
              'bestlinreg','-noverbose','-lsq9',nuc,model,xfm,modelsubject)
      subjects.append(image(modelsubject.path))
  
    # fetch templates specified on commandline
    print self.config('templates')
    templates = filter(lambda x: x.stem in self.config('templates'),subjects)

    # do pairwise registrations between atlases and templates and subjects 
    for x,y in chain(product(atlases,templates), product(templates,subjects)):
      stage('pairwise.reg').command('mb_register',x,y,out(self.xfmpath([x,y])))

    # do stuff with XFMs on all possible paths to subject
    for s in subjects:
      grids=list()
      objects=defaultdict(list)
      gridavg='output/gridavg/'+s.stem+'_grid.mnc'

      # comput all possible XFM paths to subject
      for a,t in product(atlases,templates):
        xfm=self.xfmpath([model,a,t,s])
        xfmdir=os.path.dirname(xfm)
        grid='${xfmdir}/grid.mnc'.format(xfmdir=xfmdir)
        stage('model.subject.xfm').command(
            'xfmjoin',self.xfmpath([model,a]),self.xfmpath([a,t]),self.xfmpath([t,s]),out(xfm))
        stage('model.subject.displace').command(
            'minc_displacement',model,xfm,out(grid))
          
        # transform objects from atlases
        for o in a.objects():
          kind=os.path.basename(o)
          object='${xfmdir}/${kind}'.format(xfmdir=xfmdir,kind=kind)
          stage('model.subject.objects.transform').command(
              'transform_objects',o,xfm,out(object))
          objects[kind].append(object)
        grids.append(grid)
      grids.append(out(gridavg))
    
      # average XFM per subject
      stage('model.subject.gridavg').command('mincaverage',*grids)

      # operate on surfaces
      for kind in objects.keys(): 
        # median surface per subject
        kind_base = kind.replace('.obj','')
        kind_dir  = '{output_dir}/{kind_base}/'.format(
            output_dir=self.config('output_dir'),kind_base=kind_base)
        medianobj = '{0}/{1.stem}_median.obj'.format(kind_dir,s)
        voronoi   = '{0}/{1.stem}_vorn.txt'.format(kind_dir,s)
        vorn_sa   = '{0}/{1.stem}_vorn_SA.txt'.format(kind_dir,s)

        #hack: determine the blurring kernal to use: 
        kernel = kind_base.startswith('gp_') and 3 or 5
        vorn_blur = '{0}/{1.stem}_vorn_SA_{kernel}mm_blur.txt'.format(
            kind_dir,s,kernel=kernel)

        stage('objects.median').command(
          "make_median_surfaces.pl",out(medianobj),*objects[kind])
        stage('objects.normals').command(
          "recompute_normals",medianobj,medianobj) #fix: not out()

        # voronoi of median surface
        stage('objects.voronoi').command(
          'depth_potential', '-area_voronoi',medianobj,out(voronoi))

    return tasklist

def parse_args(): 
  parser = argparse.ArgumentParser()
  parser.add_argument("-n", dest="dry_run", default=False,
    action="store_true", help="Dry run. Show what would happen.")
  parser.add_argument("-t", '--templates', nargs='+', default=(),
    help="A list of templates to use (name of the subject without .mnc extension)")
  return parser.parse_args()
  

def main():
  options = parse_args() 

  morpho  = Morphobits()
  morpho._config['templates'] = options.templates

  atlases = map(lambda x: image(x), glob.glob('input/atlases/brains/*.mnc'))
  subjects= map(lambda x: image(x), glob.glob('input/subjects/brains/*.mnc'))
  model   = image(glob.glob('input/model/brains/*.mnc')[0]) # check there is only one!

  print atlases, subjects
  tasklist= morpho.build_pipeline(atlases,subjects,model)

  if options.dry_run:
    print tasklist
  else:
    queue = multiprocqueue()
    queue.run(tasklist,processes=2)

if __name__ == '__main__': 
  main()
